{"cells":[{"cell_type":"code","source":["# To run the provided code in Databricks Community Edition, follow these steps:\n\n# Create a new notebook: Log in to your Databricks Community Edition account, and from the homepage, click \"Create\" and then \"Notebook\". Name your notebook (e.g., \"TelcoChurnAnalysis\"), and select \"Python\" as the language. Click \"Create\" to create the notebook.\n\n# Install necessary libraries: In the first cell of the notebook, install the required libraries by running the following command:\n\n## dbutils.library.installPyPI(\"pyspark\")\n\n# Upload the dataset: To upload the Telco Churn dataset to Databricks, click on the \"Data\" tab in the left sidebar. Click on the \"Add Data\" button, then click on \"Browse\" to select and upload your dataset (telco_churn.csv). Once uploaded, you'll see a file path similar to /FileStore/tables/telco_churn.csv. Copy this path to use in the code.\n\n# Add and run the code: Copy the complete code provided in the previous response, and replace the path path/to/telco_churn.csv with the actual path to your dataset from step 3. Paste the code into a new cell in your Databricks notebook, and run the cell by clicking the \"Run\" button.\n\n# After running the code, you should see the performance metrics for both the Decision Tree and Logistic Regression models printed below the cell."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d5923a06-274d-4012-9eff-133d607dc548","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# PART 1: Decision Tree Analysis using Apache Spark - 40 points"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f78fd084-b1f4-4dfa-b702-cc04c347eb01","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Import the necessary libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"577622b5-7db8-4dca-8b88-982c8f2fe507","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Load the Telco Churn dataset\nspark = SparkSession.builder.appName(\"TelcoChurnDecisionTree\").getOrCreate()\ndata = spark.read.csv(\"dbfs:/FileStore/shared_uploads/jindalkalash298@gmail.com/poc1/v2/WA_Fn_UseC__Telco_Customer_Churn.csv\", header=True, inferSchema=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"55b93deb-ff30-4257-beca-b6af3d1b9f4c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Convert TotalCharges to float data type\ndata = data.withColumn(\"TotalCharges\", col(\"TotalCharges\").cast(\"float\"))\ndata = data.na.drop()  # Remove rows with null or empty values"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"59671b11-1b73-425c-b624-a57c6cb6877a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Prepare the data for modeling\n\ncategorical_features = [\n    'gender',\n    'SeniorCitizen',\n    'Partner',\n    'Dependents',\n    'PhoneService',\n    'MultipleLines',\n    'InternetService',\n    'OnlineSecurity',\n    'OnlineBackup',\n    'DeviceProtection',\n    'TechSupport',\n    'StreamingTV',\n    'StreamingMovies',\n    'Contract',\n    'PaperlessBilling',\n    'PaymentMethod'\n]\n\nnumerical_features = [\n    'tenure',\n    'MonthlyCharges',\n    'TotalCharges'\n]\n\nindexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in categorical_features]\nassembler = VectorAssembler(inputCols=[column+\"_index\" for column in categorical_features] + numerical_features, outputCol=\"features\")\nlabel_indexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b0dab8c2-417f-40a8-87da-8f95a41671cd","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Create the Decision Tree model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n# Create the Logistic Regression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"442b8b6e-500b-40ad-b2c0-e6e11b3b7c52","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Train and evaluate the models\ntrain_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\nevaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nevaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\nevaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\nevaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"64d6026d-4e21-442d-9371-6cec3f6fd988","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["for model_name, model in [(\"Decision Tree\", dt), (\"Logistic Regression\", lr)]:\n    pipeline = Pipeline(stages=indexers + [assembler, label_indexer, model])\n    model_fitted = pipeline.fit(train_data)\n    predictions = model_fitted.transform(test_data)\n    \n    accuracy = evaluator_accuracy.evaluate(predictions)\n    precision = evaluator_precision.evaluate(predictions)\n    recall = evaluator_recall.evaluate(predictions)\n    f1_score = evaluator_f1.evaluate(predictions)\n    \n    print(f\"{model_name} Performance:\")\n    print(f\"Accuracy: {accuracy:.3f}\")\n    print(f\"Precision: {precision:.3f}\")\n    print(f\"Recall: {recall:.3f}\")\n    print(f\"F1 Score: {f1_score:.3f}\")\n    print(\"------------------------------------------------\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dea7c7d6-c35d-44b4-8353-36937ac24a49","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Decision Tree Performance:\nAccuracy: 0.789\nPrecision: 0.776\nRecall: 0.789\nF1 Score: 0.779\n------------------------------------------------\nLogistic Regression Performance:\nAccuracy: 0.811\nPrecision: 0.802\nRecall: 0.811\nF1 Score: 0.804\n------------------------------------------------\n"]}],"execution_count":0},{"cell_type":"code","source":["#PART 3: Explain the following: Under what circumstances would you adopt Logistic Regression Analysis Technique?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b9821337-2b06-44bb-95e2-ca5883d1543d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Logistic Regression is a widely used statistical method for analyzing a dataset in which the dependent\n# variable (label) is binary or categorical. The technique allows you to predict the probability of an\n# outcome based on the values of the independent variables (features). In contrast to linear regression,\n# logistic regression is used when the response variable is categorical.\n#\n# Some circumstances in which you would adopt Logistic Regression Analysis Technique are:\n#\n# 1. Binary classification problems: Logistic Regression is particularly suited for binary classification\n# problems, i.e., when there are two possible outcomes (e.g., churn or no churn, spam or not spam).\n#\n# 2. Probabilistic interpretation: When you require not only a class label but also the probability of\n# belonging to a particular class, logistic regression provides an interpretable probabilistic output.\n#\n# 3. Linear relationships between features and log-odds: Logistic Regression is appropriate when there\n# is an approximate linear relationship between the features and the log-odds of the outcome.\n#\n# 4. Simplicity and interpretability: Logistic Regression is relatively simple, computationally efficient,\n# and easy to interpret compared to some other machine learning techniques, such as deep learning or\n# ensemble methods.\n#\n# 5. Regularization and feature selection: Logistic Regression supports regularization techniques like L1\n# and L2 regularization, which help prevent overfitting and can be used for feature selection.\n#\n# It's important to note that Logistic Regression may not be the best choice when dealing with non-linear\n# relationships or when there are complex interactions between features. In these cases, more advanced\n# techniques like decision trees, random forests, or neural networks may be more appropriate.\n# ----------------------------------------------------------------------------"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2973d338-0bcb-4cef-a2da-a6239c514828","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9d7b4084-fe19-4128-b902-947040bb7e68","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"lance-spark-1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1018155064793300}},"nbformat":4,"nbformat_minor":0}
